[ { "title": "Usefull Linux Commands", "url": "/posts/Linux-Commands/", "categories": "guides, linux", "tags": "servers, guides, homelab", "date": "2022-09-03 01:55:00 +0200", "snippet": "Update Your SystemTo update the repositories run the following command in the terminal:Debian / Ubuntusudo apt update #If you are not logged in as the root user, make sure to use &quot;sudo&quot;Fedorasudo dnf update #If you are not logged in as the root user, make sure to use &quot;sudo&quot;To install the available updates to theDebian / Ubuntusudo apt upgrade #If you are not logged in as the root user, make sure to use &quot;sudo&quot;Fedorasudo dnf upgrade #If you are not logged in as the root user, make sure to use &quot;sudo&quot;Copying FilesIf you are on the computer from which you want to send file to a remote computer:scp /file/to/send username@remote:/where/to/putHere the remote can be a FQDN(hostname) or an IP address.On the other hand if you are on the computer wanting to receive file from a remote computer:scp username@remote:/file/to/send /where/to/putscp can also send files between two remote hosts:scp username@remote_1:/file/to/send username@remote_2:/where/to/put" }, { "title": "Installing Uptime Kuma using Docker", "url": "/posts/Uptime_Kuma/", "categories": "docker", "tags": "servers, guides, homelab, docker, uptime_kuma", "date": "2022-07-16 17:55:00 +0200", "snippet": "Uptime KumaIt is a self-hosted monitoring tool like ‚ÄúUptime Robot‚Äù.Features Monitoring uptime for HTTP(s) / TCP / HTTP(s) Keyword / Ping / DNS Record / Push / Steam Game Server. Fancy, Reactive, Fast UI/UX. Notifications via Telegram, Discord, Gotify, Slack, Pushover, Email (SMTP), and 90+ notification services, click here for the full list. 20 second intervals. Multi Languages Multiple Status Pages Map Status Page to Domain Ping Chart Certificate Info Proxy Support 2FA availableHow to Install:Dockerdocker run -d --restart=always -p 3001:3001 -v uptime-kuma:/app/data --name uptime-kuma louislam/uptime-kuma:1Please use a local volume only. Other types such as NFS are not supported.Browse to http://localhost:3001 after starting.Non-DockerRequired Tools: Node.js &amp;gt;= 14 Git pm2 - For run in background# Update your npm to the latest versionnpm install npm -ggit clone https://github.com/louislam/uptime-kuma.gitcd uptime-kumanpm run setup# Option 1. Try itnode server/server.js# (Recommended) Option 2. Run in background using PM2# Install PM2 if you don&#39;t have it: npm install pm2 -g &amp;amp;&amp;amp; pm2 install pm2-logrotate# Start Serverpm2 start server/server.js --name uptime-kumaBrowse to http://localhost:3001 after starting.More useful PM2 Commands# If you want to see the current console outputpm2 monit# If you want to add it to startuppm2 save &amp;amp;&amp;amp; pm2 startupüñº More ScreenshotsLight Mode:Status Page:Settings Page:Telegram Notification Sample:" }, { "title": "Installing EmulaterJS on Docker", "url": "/posts/EmulaterJS/", "categories": "guides, docker", "tags": "servers, guides, games, os", "date": "2022-07-08 21:55:00 +0200", "snippet": "Before you begin you need to create data and config folders on your local machineExample:mkdir /home/user/docker/emulaterjs/datamkdir /home/user/docker/emulaterjs/config" }, { "title": "Fedora Tweaks", "url": "/posts/Fedora/", "categories": "guides, linux", "tags": "servers, guides, fedora, os", "date": "2022-06-28 21:55:00 +0200", "snippet": "Speed up DNFFirst things first, after installing fedora, you should make the dnf package manager faster by adding 2 lines in /etc/dnf/dnf.confTo edit the file run:sudo nano /etc/dnf/dnf.confThen add these lines to the bottom of the page:max_parallel_downloads=10fastestmirror=TrueReboot and run:sudo dnf updateInstall Brave Browser on Fedora:sudo dnf install dnf-plugins-coresudo dnf config-manager --add-repo https://brave-browser-rpm-release.s3.brave.com/x86_64/sudo rpm --import https://brave-browser-rpm-release.s3.brave.com/brave-core.ascsudo dnf install brave-browser" }, { "title": "Installing Speedtest Tracker using docker", "url": "/posts/Speedtest-Tracker/", "categories": "guides, docker", "tags": "servers, guides, docker, speedtest", "date": "2022-06-12 21:55:00 +0200", "snippet": "To install speedtest tracker you need to create the following folder on the host machine:mkdir -p /home/user/docker/speedtest-tracker/config# user will be your username on the host machine.Once the directory is created, just run the following docker command:sudo docker run -d \\ --name=speedtest \\ -p 8765:80 \\ -v /home/user/docker/speedtest-tracker/config:/config \\ -e OOKLA_EULA_GDPR=true \\ --restart unless-stopped \\ henrywhitaker3/speedtest-tracker:dev-arm# Remember to change `user` to your username.This will use OOKLA speedtest.net to determine the internet speed, servers can be changed and also updated vir the UI, once deployed." }, { "title": "Installing MeshCentral on AWS", "url": "/posts/MeshCentral/", "categories": "guides, cloud-hosting", "tags": "servers, guides, meshcentral, aws, cloud", "date": "2022-06-12 21:55:00 +0200", "snippet": "MeshCentralMeshCentral is a free open source web-based remote computer management software. Youcould setup your own management server on a local network or on the internet and remotecontrol and manage computers that runs either Windows* or Linux* OS.Installing NodeJSThe first prerequisite is to ensure NodeJS is installed on the system. We will install the node version manager, activate it, then install the LTS version of NodeJS.sudo add-apt-repository universesudo apt updatesudo apt install nodejs -ysudo apt install npm -y##You can verify the versions of NodeJS and NPM just installed with the following commands:node -vnpm -vPort PermissionsOn Linux, as a security feature, ports below 1024 are reserved for processes running as ‚Äúroot‚Äù user. In our case, we need MeshCentral to listen/run on ports 80 and 443. To accomplish this, we first need to discover where NodeJS runs from:whereis nodenode: /usr/bin/node /usr/include/node /usr/share/man/man1/node.1.gzIn this case, the result shows NodeJS binaries are found at /usr/bin/node. We will this path in the next command, which will allow NodeJS to utilize ports below 1024. Note that these permissions may sometimes be lost when updating the Linux Kernel and the command may need to be run again. 1)sudo setcap cap_net_bind_service=+ep /usr/bin/nodeInstalling MeshCentralWe are finally ready to install MeshCentral! We use NPM to install the latest version of MeshCentral with the command below:- !!DO NOT USE &quot;SUDO&quot; FOR THIS COMMAND!! -npm install meshcentralAfter the installation completes we can manually run MeshCentral for the first time:node ./node_modules/meshcentralAutomatically Starting the ServerSince Ubuntu supports systemd, we are going to use that to auto start MeshCentral in the background. First we need to know what our own username and group are. The simplest way to find this info is (from your home folder) runls -lDoing so should give output similar to this example below:drwxr-xr-x 2 user default 4096 Jul 20 00:03 Desktopdrwxr-xr-x 2 user default 4096 Jul 20 00:03 Documentsdrwxr-xr-x 2 user default 4096 Jul 20 00:03 Download...Make note of the username and group. In the sample above, the username is user and the group is default.We will also need to know the path where NodeJS binaries are at. to find this enter:whereis nodeNode is usually installed at /usr/bin/node but if your check above shows a different path, make note of it and enter it into the appropriate place in the file we are about to create.We will need all of this information to create the description file for the MeshCentral service we create. To create this description file, enter:sudo nano /etc/systemd/system/meshcentral.serviceIn this new file, enter the following lines:[Unit]Description=MeshCentral Server[Service]Type=simpleLimitNOFILE=1000000ExecStart=/usr/bin/node /home/user/node_modules/meshcentralWorkingDirectory=/home/userEnvironment=NODE_ENV=productionUser=userGroup=defaultRestart=always# Restart service after 10 seconds if node service crashesRestartSec=10# Set port permissions capabilityAmbientCapabilities=cap_net_bind_service[Install]WantedBy=multi-user.targetBe sure you set the username and group values correctly for your specific installation.Notice that the ExecStart and WorkingDirectory lines include the path to the user‚Äôs home folder. So make sure you have the correct username in there. Also be sure to double check the path to NodeJS in the ExecStart line.Once we have this file created we can now enable, start, stop and disable MeshCentral:sudo systemctl enable meshcentral.servicesudo systemctl start meshcentral.servicesudo systemctl stop meshcentral.servicesudo systemctl disable meshcentral.serviceRun the first two commands to enable then start MeshCentral. Enabling the service will make MeshCentral start up automatically each time the computer restarts.Once MeshCentral is started, you can access it via web browser just as we did earlier. You should now refer to the MeshCentral User‚Äôs Guide or this wiki‚Äôs configuration guides for information about on how to further configure and use MeshCentral." }, { "title": "Installing Pi-hole", "url": "/posts/Pi-hole/", "categories": "guides, docker", "tags": "servers, guides, homelab, pi-hole", "date": "2022-06-02 01:55:00 +0200", "snippet": "Using Docker:When setting up Pi-hole in a Docker container, you‚Äôll first need to create a Docker volume to store the Pi-hole application and DNS configuration.Open a terminal, then run the below commands for Docker to create two volumes (volume create) named pihole_app and dns_config. You can also change the names according to your preference.sudo docker volume create pihole_appsudo docker volume create dns_configNext, verify that the Docker volumes have been created successfully by running the following command which lists all Docker volumes available on your machine.docker volume lsBelow, you see two newly created volumes named pihole_app and dns_config.Running Pi-hole in Docker Container with Environment VariablesNow that you have two persistent volumes available, you are ready to run a Docker container using Pi-hole‚Äôs base Docker image. But first, you‚Äôll need to note your local IP address.Run the below command to get your local IP address. Your local IP address is necessary to run the single Docker command properly.ifconfig NOTE: If ifconfig is not installed, you first need to install net-tools with the following command: sudo apt install net-tools Once you‚Äôve got your IP address, run the command below to pull the pihole/pihole base image from Docker hub. Replace the values accordingly using the table below as your reference. The table below explains each flag of the command‚Äôs purpose.docker run --name=pihole -e TZ=Africa/Johannesburg -e WEBPASSWORD=password -e SERVERIP=YourIPAddressHere -v pihole_app:/etc/pihole -v dns_config:/etc/dnsmasq.d -p 81:80 -p 53:53/tcp -p 53:53/udp --restart=unless-stopped pihole/piholePi-hole Docker Command Flags: Command Flags Definition --name=pihole - Names a Docker container as pihole. There will be an error if a container with the same name already exists on your machine -e TZ=Asia/Manila - Environment variable for time zone. Asia/Manila was used for this tutorial, but you can input anything that has the same format listed in on a GitHub gist. -e WEBPASSWORD=password - Sets a password for the Pi-hole interface. -e SERVERIP=YourIPAddressHere - Set your IP address for the Docker container. You will use this again later for making Pi-hole work. -v pihole_app:/etc/pihole - Mounts the volume pihole_app and use subdirectory /etc/pihole for storing the Pi-hole files -v dns_config:/etc/dnsmasq.d - Mounts the volume dns_config and use subdirectory /etc/dnsmasq.d for storing DNS configurations as required. -p 81:80 -p 53:53/tcp -p 53:53/udp - Maps the ports of host machine to the ports of the Docker container (port 81 in host machine maps to port 80 of Docker container) ‚Äîrestart=unless-stopped - Sets a restart policy so the Docker container always restarts unless it is manually stopped by the user. pihole/pihole - Tells the docker run command to use the official pihole/pihole base image from Docker hub.On Debian/Ubuntu:One-Step Automated Install¬∂Those who want to get started quickly and conveniently may install Pi-hole using the following command:curl -sSL https://install.pi-hole.net | bashInfoPiping to bash is a controversial topic, as it prevents you from reading code that is about to run on your system.If you would prefer to review the code before installation, we provide these alternative installation methods.Option 1: Clone our repository and rungit clone --depth 1 https://github.com/pi-hole/pi-hole.git Pi-holecd &quot;Pi-hole/automated install/&quot;sudo bash basic-install.shOption 2: Manually download the installer and runwget -O basic-install.sh https://install.pi-hole.netsudo bash basic-install.sh" }, { "title": "Installing Jellyfin using docker", "url": "/posts/Jellyfin/", "categories": "guides, docker", "tags": "servers, guides, homelab, jellyfin, media", "date": "2022-06-02 01:55:00 +0200", "snippet": "Jellyfin can be installed using docker-compose or the terminal:docker-compose:to make use of this method, first create a new file /docker/jellyfin/docker-compose.ymlenter the following code in the file and save---version: &quot;3&quot;services: jellyfin: image: lscr.io/linuxserver/jellyfin:latest container_name: jellyfin environment: - PUID=1000 - PGID=1000 - TZ=Europe/London - JELLYFIN_PublishedServerUrl=192.168.0.5 #optional volumes: - /path/to/library:/config - /path/to/tvseries:/data/tvshows - /path/to/movies:/data/movies ports: - 8096:8096 - 8920:8920 #optional - 7359:7359/udp #optional - 1900:1900/udp #optional restart: unless-stoppedInside the jellyfin directory run:sudo docker-compose up -aTerminaldocker run -d \\ --name=jellyfin \\ -e PUID=1000 \\ -e PGID=1000 \\ -e TZ=Europe/London \\ -e JELLYFIN_PublishedServerUrl=192.168.0.5:123 `#optional` \\ -p 8096:8096 \\ -p 8920:8920 `#optional` \\ -p 7359:7359/udp `#optional` \\ -p 1900:1900/udp `#optional` \\ -v /path/to/library:/config \\ -v /path/to/tvseries:/data/tvshows \\ -v /path/to/movies:/data/movies \\ --restart unless-stopped \\ lscr.io/linuxserver/jellyfin:latest" }, { "title": "Setting up SMB / CIFS", "url": "/posts/SMB-CIFS/", "categories": "guides, linux", "tags": "servers, guides, homelab, smb, cifs", "date": "2022-06-01 01:55:00 +0200", "snippet": "You need to edit the fstab file on your system to auto mount an external drive on boot.1 - Run the following command:sudo nano /etc/fstab2 - Edit the file and add the following line at the bottom of the file://location/of/drive /media/mnt cifs username=user,password=password,uid=1000,gid=1000 0 03 - Run the mount command to mount the directories specified:sudo mount -aIf Smb is not installed, it can be installed by running:sudo apt-get install smbclient" }, { "title": "Installing Portainer Using Docker", "url": "/posts/Portainer/", "categories": "guides, docker", "tags": "servers, guides, homelab, docker, portainer", "date": "2022-06-01 01:55:00 +0200", "snippet": "1 - Create the volume that Portainer Server will use to store its database:docker volume create portainer_data2 - Download and install the Portainer Server container:sudo docker run -d \\ -p 8000:8000 \\ -p 9443:9443 \\ --name portainer \\ --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v portainer_data:/data \\ portainer/portainer-ce:latestLogging In:Now that the installation is complete, you can log into your Portainer Server instance by opening a web browser and going to:https://localhost:9443Replace ‚Äò‚Äòlocalhost‚Äô‚Äô with the relevant IP address or FQDN if needed, and adjust the port if you changed it earlier.You will be presented with the initial setup page for Portainer Server.Upgrading PortainerTo upgrade Portainer we need to stop and remove the current Portainer instance.sudo docker stop portainersudo docker rm portainerNow we need to pull the latest image again, otherwise docker will just use the existing image named ‚Äúlatest‚Äùdocker pull portainer/portainer-ce:latestNow launch the container with docker run in the terminal:docker run -d \\ -p 8000:8000 \\ -p 9443:9443 \\ --name portainer \\ --restart=always \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v portainer_data:/data \\ portainer/portainer-ce:latest" }, { "title": "Installing ownCloud using Docker", "url": "/posts/OwnCloud/", "categories": "guides, docker", "tags": "servers, guides, homelab, docker, owncloud", "date": "2022-06-01 01:55:00 +0200", "snippet": "To Install OwnCloud you first need to have docker installed.Open a terminal and enter the following command.sudo docker run --name owncloud -d -p 70:80 restart:always owncloud:latestIn the docker container you need to install SMB Client with the following code if you want to use an SMB or CIFS mounted external drive.apt-get update &amp;amp;&amp;amp; apt-get install -y smbclient &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/*To access ownCloud go to:http://your-ip-here:70" }, { "title": "Installing Docker on Linux", "url": "/posts/Installing-Docker/", "categories": "guides, docker, linux", "tags": "servers, guides, homelab, docker", "date": "2022-06-01 01:55:00 +0200", "snippet": "Install using the repositoryBefore you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.Set up the repository:1 - Update the ‚Äò‚Äòapt‚Äô‚Äô package index and install packages to allow ‚Äò‚Äòapt‚Äô‚Äô to use a repository over HTTPS:sudo apt-get update sudo apt-get install ca-certificates curl gnupg lsb-release2 - Add Docker‚Äôs official GPG key:sudo mkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg3 - Use the following command to set up the repository:echo &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &amp;gt; /dev/nullInstall Docker Engine:Update the ‚Äò‚Äòapt‚Äô‚Äô package index, and install the //latest version// of Docker Engine, containerd, and Docker Compose, or go to the next step to install a specific version:sudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-pluginConfirm your docker installation was sucessfull by runningsudo systemctl status dockerThe output should show ‚Äúactive‚Äù" }, { "title": "Gitlab / Github", "url": "/posts/Gitlab/", "categories": "guides, linux", "tags": "servers, guides, homelab", "date": "2022-06-01 01:55:00 +0200", "snippet": "To clone a repository to your local machine you need to run the following code:Remember that you need to be in the directory you want to clone it to.git clone https://pops199.github.ioOr if you want to clone it to a specific folder you can add the path at the endgit clone https://pops199.github.io /path/you/want/to/save/toOnce you are done editing the files, you need to save, commit and push the files back to github.1. Save the file in the editor you are using2. Check the status of your changesgit statusThe output should look something like this:On branch mainYour branch is up to date with &#39;origin/main&#39;.Changes not staged for commit: (use &quot;git add/rm &amp;lt;file&amp;gt;...&quot; to update what will be committed) (use &quot;git restore &amp;lt;file&amp;gt;...&quot; to discard changes in working directory) modified: _config.yml deleted: _posts/Gitlab.mdUntracked files: (use &quot;git add &amp;lt;file&amp;gt;...&quot; to include in what will be committed) _posts/2022-05-31-Gitlab.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)3. Add the changes to your repo (Again be sure to be in the directory of your repo)git add .4. Commit the changes and add a commentgit commit -m &quot;Your comment about changes made&quot;5. Finally push the files to your github repogit pushThe files will now be visible and changes on your github website.Pushing files from more than one computerIf you pushed files to your repo and now needs to push from a different computer again, the files first needs to be merged by running:git config pull.rebase falsethen run:git pullNow the files should be synced and merged, now you can push again to the same repo from the computer." }, { "title": "Installing Dashy using Docker", "url": "/posts/Dashy/", "categories": "guides, docker", "tags": "servers, guides, homelab, docker, dashy", "date": "2022-06-01 00:55:00 +0200", "snippet": "Deploy with DockerDashy has a built container image hosted on Docker Hub. You will need Docker installed on your system.Run the following command in the terminal:sudo docker run -d \\ -p 8080:80 \\ -v /root/my-local-conf.yml:/app/public/conf.yml \\ --name dashy \\ --restart=always \\ lissy93/dashy:latestExplanation of the above options:-d Detached mode (not running in the foreground of your terminal)-p The port that should be exposed, and the port it should be mapped to in your host system [host-port][container-port], leave the container port as is-v Specify volumes, to pass data from your host system to the container, in the format of [host-path]:[container-path], you can use this to pass your config file, directory of assets (like icons), custom CSS or web assets (like favicon.ico, manifest.json etc)--name Give your container a human-readable name--restart=always Spin up the container when the daemon starts, or after it has been stoppedlissy93/dashy:latest This last option is the image the container should be built from, you can also use a specific version or architecture type, by replacing :latest with one of the tagsFor all available options, and to learn more, see the Docker Run DocsDashy is also available through GHCR: docker pull ghcr.io/lissy93/dashy:latestIf you‚Äôre deploying Dashy on a modern ARM-based board, such as a Raspberry Pi (2+), then you‚Äôll need to use one of Dashy‚Äôs ARM images. Set the base image + tag to either lissy93/dashy:arm64v8 or lissy93/dashy:arm32v7, depending on your system architecture. You can also use the multi-arch image, which should work on all system architectures.The image defaults to :latest, but you can instead specify a specific version, e.g. docker pull lissy93/dashy:release-1.5.0Using Docker ComposeUsing Docker Compose can be useful for saving your specific config in files, without having to type out a long run command each time. Save compose config as a YAML file, and then run docker compose up -d (optionally use the -f flag to specify file location, if it isn‚Äôt located at ./docker-compose.yml), -d is detached mode (not running in the foreground of your terminal). Compose is also useful if you are using clusters, as the format is very similar to stack files, used with Docker Swarm.The following is a complete example of a docker-compose.yml for Dashy. Run it as is, or uncomment the additional options you need.---version: &quot;3.8&quot;services: dashy: # To build from source, replace &#39;image: lissy93/dashy&#39; with &#39;build: .&#39; # build: . image: lissy93/dashy container_name: Dashy # Pass in your config file below, by specifying the path on your host machine # volumes: # - /root/my-config.yml:/app/public/conf.yml ports: - 4000:80 # Set any environmental variables environment: - NODE_ENV=production # Specify your user ID and group ID. You can find this by running `id -u` and `id -g` # - UID=1000 # - GID=1000 # Specify restart policy restart: unless-stopped # Configure healthchecks healthcheck: test: [&#39;CMD&#39;, &#39;node&#39;, &#39;/app/services/healthcheck&#39;] interval: 1m30s timeout: 10s retries: 3 start_period: 40sYou can use a different tag, by for example setting image: lissy93/dashy:arm64v8, or pull from GHCR instead by setting image: ghcr.io/lissy93/dashy.If you are building from source, and would like to use one of the other Dockerfiles, then under services.dashy first set context: ., then specify the the path to the dockerfile, e.g. dockerfile: ./docker/Dockerfile-arm32v7" } ]
